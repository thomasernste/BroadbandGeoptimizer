{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    # If PYTHONPATH is not set, findspark and findspark.init() will find it on your machine \n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import spark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master('local') \\\n",
    "        .appName(\"BroadbandScout\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import regexp_replace, col\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "pathname_input = 's3a://sparkforinsightproject/HPI_AT_BDL_tract.csv'\n",
    "\n",
    "pathname_output = 's3a://sparkforinsightproject/database_data/sparkdf_broadband_output_2'\n",
    "\n",
    "\n",
    "def etl_hpi_to_tract(input_data_txt):\n",
    "    \n",
    "\n",
    "    rdd_HPI_to_CENSUS = sc.textFile(input_data_txt)\n",
    "\n",
    "\n",
    "    rdd_HPI_to_TRACT = rdd_HPI_to_CENSUS\\\n",
    "                                   .map(lambda x: x.encode('ascii', 'ignore'))\\\n",
    "                                   .map(lambda x: x.split(','))\\\n",
    "                                   .map(lambda l: (l[0], l[1], l[2], l[4]))\n",
    "\n",
    "    \n",
    "\n",
    "    hpi_schema = StructType([\n",
    "        StructField(\"tract\", StringType(), True),\n",
    "        StructField(\"state_abbr\", StringType(), True),\n",
    "        StructField(\"year\", StringType(), True),\n",
    "        StructField(\"annual_change\", StringType(), True),\n",
    "        StructField(\"hpi\", FloatType(), True),\n",
    "        StructField(\"hpi1990\", FloatType(), True),\n",
    "        StructField(\"hpi2000\", FloatType(), True)\n",
    "        ])\n",
    "\n",
    "\n",
    "    df_HPI_to_TRACT = spark.read.csv(input_data_txt, header=True, schema=hpi_schema)#\\\n",
    "\n",
    "\n",
    "    df_HPI_to_TRACT = df_HPI_to_TRACT\\\n",
    "                               .withColumnRenamed(\"tract\", \"census_tract\")\\\n",
    "                               .withColumnRenamed(\"state_abbr\", \"state\")\n",
    "\n",
    "\n",
    "    # This code selects and saves just seven of the 16 columns from the \n",
    "    # original file that have some clear potential value for the database.\n",
    "\n",
    "    df_HPI_to_TRACT = df_HPI_to_TRACT\\\n",
    "                                       .select(\n",
    "                                       \"census_tract\",\n",
    "                                       \"state\",\n",
    "                                       \"year\",\n",
    "                                       \"hpi\")\n",
    "    \n",
    "    df_hpi_tract_2017_wa = df_HPI_to_TRACT.where(col('year').isin({'2017'})).where(col('state').isin({'WA'}))\n",
    "\n",
    "    return df_hpi_tract_2017_wa\n",
    "\n",
    "def main():\n",
    "    input_data_txt = sys.argv[1]\n",
    "    extract_transform_load_broadband(input_data_txt)\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output_hpi_to_tract = etl_hpi_to_tract(pathname_input)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
