{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script extracts, transforms, and loads a dataset that includes nine columns. The primary value \n",
    "# of this dataset for this project is that it links all US zip codes to GPS coordinates -- the \n",
    "# provided GPS coordinates are the latitude and longitude for the center of the given zip code. \n",
    "# Additionally, the dataset includes columns matching all US zip codes: primary city; \"acceptable\n",
    "# cities,\" a variable which acknowledges that some zip codes match with two or more cities; the county \n",
    "# for the corresponding zip code; the state; the time zone; and the estimated population in 2015.\n",
    "\n",
    "# Data was found here: https://www.unitedstateszipcodes.org/zip-code-database/\n",
    "\n",
    "# If PYTHONPATH is not set, findspark and findspark.init() will find it on your machine \n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import spark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql.functions import size\n",
    "\n",
    "# schemaString = 'something'\n",
    "\n",
    "# fields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master('local') \\\n",
    "        .appName(\"BroadbandScout\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "\n",
    "input_pathname_ZIP_GPS = 's3a://sparkforinsightproject/usps_zip_code_database.csv'\n",
    "\n",
    "output_pathname_ZIP_GPS = \"s3a://sparkforinsightproject/database_data/transformed_ZIP_CODES_to_GPS\"\n",
    "\n",
    "input_pathname = 's3a://sparkforinsightproject/usps_zip_code_database.csv'\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import trim\n",
    "\n",
    "def etl_ZIP_to_GPS(input_pathname):\n",
    "\n",
    "    \n",
    "    zip_to_gps_schema = StructType([\n",
    "    StructField(\"zip\", StringType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"decommissioned\", StringType(), True),\n",
    "    StructField(\"primary_city\", StringType(), True),\n",
    "    StructField(\"acceptable_cities\", StringType(), True),\n",
    "    StructField(\"unacceptable_cities\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"county\", StringType(), True),\n",
    "    StructField(\"timezone\", StringType(), True),\n",
    "    StructField(\"area_code\", StringType(), True),\n",
    "    StructField(\"world_region\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"latitude\", FloatType(), True),\n",
    "    StructField(\"longitude\", FloatType(), True),\n",
    "    StructField(\"irs_estimated_population_2015\", IntegerType(), True)\n",
    "    ])\n",
    "\n",
    "    df_ZIP_CODES_GPS = spark.read.csv(input_pathname, sep=',', header=True, schema=zip_to_gps_schema)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_ZIP_CODES_GPS = df_ZIP_CODES_GPS.select('zip', 'primary_city', 'acceptable_cities', 'state', 'county',\n",
    "                            'timezone', 'latitude', 'longitude', 'irs_estimated_population_2015')\\\n",
    "                    .withColumn(\"county\", trim(df_ZIP_CODES_GPS. county))\\\n",
    "                    .withColumn(\"acceptable_cities\", trim(df_ZIP_CODES_GPS. acceptable_cities))\\\n",
    "                    .withColumnRenamed(\"zip\", \"zip_code\")\\\n",
    "                    .withColumnRenamed(\"irs_estimated_population_2015\", \"population_2015\")\\\n",
    "                    .withColumnRenamed(\"acceptable_cities\", \"accepted_cities\")\n",
    "    \n",
    "    return df_ZIP_CODES_GPS\n",
    "\n",
    "def main():\n",
    "    input_data_txt = sys.argv[1]\n",
    "    etl_ZIP_to_GPS(input_pathname)\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        main()\n",
    "\n",
    "    \n",
    "# output_df_HPI_to_CENSUS_TRACTS = etl_ZIP_to_GPS(input_pathname_ZIP_GPS)\n",
    "\n",
    "# output_df_HPI_to_CENSUS_TRACTS.show(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
